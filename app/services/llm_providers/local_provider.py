"""Local LLM Provider implementation (Ollama, LocalAI compatible) - placeholder."""
from typing import List, Dict, Any, Optional
import logging

from .base_provider import (
    BaseLLMProvider,
    LLMMessage,
    LLMResponse,
    ModelInfo,
    ProviderType
)

logger = logging.getLogger(__name__)

# Local LLM provider will be implemented in a future update
# This placeholder prevents import errors
